Tr√®s bien‚ÄØ! Voici une version **recr√©√©e et structur√©e proprement** de votre `README.md`, incluant un sch√©ma Mermaid, des sections claires et professionnelles, tout en conservant l‚Äôesprit de votre message original.

---

# ü©∫ Pipeline de Traitement de Contenu M√©dical

Ce projet met en ≈ìuvre un pipeline distribu√© pour ing√©rer, enrichir, stocker et interroger du contenu m√©dical. Il s'appuie sur une architecture microservices, Kafka pour la communication asynchrone, MongoDB pour le stockage et LM Studio pour l‚Äôenrichissement par IA.

---

## üìë Table des Mati√®res

* [üöÄ Aper√ßu du Projet](#-aper√ßu-du-projet)
* [‚ú® Fonctionnalit√©s Cl√©s](#-fonctionnalit√©s-cl√©s)
* [üß± Architecture Globale](#-architecture-globale)

  * [üìä Diagramme Mermaid](#-diagramme-mermaid)
  * [üîÅ D√©tail du Flux de Donn√©es](#-d√©tail-du-flux-de-donn√©es)
* [üõ†Ô∏è Technologies Utilis√©es](#-technologies-utilis√©es)
* [‚öôÔ∏è Pr√©requis](#-pr√©requis)
* [üì¶ Installation](#-installation)
* [‚ñ∂Ô∏è Lancement des Services](#Ô∏è-lancement-des-services)
* [üîó Points d'Acc√®s API](#-points-dacc√®s-api)
* [üìÅ Structure du Projet](#-structure-du-projet)
* [üß© Am√©liorations Possibles](#-am√©liorations-possibles)

---

## üöÄ Aper√ßu du Projet

L'objectif est de construire un syst√®me **scalable** et **modulaire** pour traiter du texte m√©dical. Les messages sont transmis entre microservices via **Apache Kafka**, enrichis par un mod√®le de langage (via **LM Studio**), stock√©s dans **MongoDB** et consultables via des API **REST** et **GraphQL**.

---

## ‚ú® Fonctionnalit√©s Cl√©s

‚úÖ Ingestion via API REST ou gRPC
‚úÖ Traitement asynchrone et d√©coupl√© via Kafka
‚úÖ Classification automatique par mots-cl√©s
‚úÖ Enrichissement intelligent via LM Studio
‚úÖ Stockage durable dans MongoDB
‚úÖ Acc√®s flexible via GraphQL ou REST

---

## üß± Architecture Globale

### üìä Diagramme Mermaid

```mermaid
graph TD
    subgraph Clients
        ClientREST[Client REST]
        ClientGRPC[Client gRPC]
        ClientGraphQL[Client GraphQL]
    end

    subgraph Entr√©e
        APIGW["API Gateway (REST/GraphQL)"]
        GRPCReceiver["Content Receiver (gRPC)"]
    end

    subgraph Kafka
        TopicIncoming["Topic: incoming-medical-content"]
        TopicClassified["Topic: classified-content"]
    end

    subgraph Traitement
        Classifier["Classifier Service"]
        LMStudio["LM Studio (externe)"]
    end

    subgraph Stockage
        Storage["Storage Service"]
        Mongo[(MongoDB)]
    end

    subgraph Requ√™te
        GraphQLQuery["Query Service (Apollo Server)"]
    end

    %% Relations
    ClientREST -->|POST /api/content| APIGW --> TopicIncoming
    ClientGRPC --> GRPCReceiver --> TopicIncoming
    Classifier -->|Consomme| TopicIncoming
    Classifier -->|Appel POST| LMStudio --> Classifier -->|Publie| TopicClassified
    Storage -->|Consomme| TopicClassified --> Mongo
    ClientGraphQL -->|/graphql| APIGW
    ClientGraphQL --> GraphQLQuery --> Storage

    classDef service fill:#E3F2FD,stroke:#2196F3;
    classDef db fill:#E8F5E9,stroke:#4CAF50;
    classDef kafka fill:#FFF3E0,stroke:#FF9800;
    classDef external fill:#FFF9C4,stroke:#FBC02D;
    classDef client fill:#F5F5F5,stroke:#9E9E9E;

    class APIGW,GRPCReceiver,Classifier,Storage,GraphQLQuery service;
    class Mongo db;
    class TopicIncoming,TopicClassified kafka;
    class LMStudio external;
    class ClientREST,ClientGRPC,ClientGraphQL client;
```

---

## üîÅ D√©tail du Flux de Donn√©es

1. **Ingestion**

   * Un client envoie une requ√™te `POST /api/content` (REST) ou appelle `ProcessContent` (gRPC).
   * Le message est publi√© sur `incoming-medical-content`.

2. **Classification & Enrichissement**

   * Le `Classifier Service` consomme les messages.
   * Classification simple bas√©e sur mots-cl√©s.
   * Envoi du texte √† **LM Studio** pour r√©sum√©/analyse.
   * R√©sultat enrichi publi√© sur `classified-content`.

3. **Stockage**

   * Le `Storage Service` consomme le topic `classified-content`.
   * Les donn√©es sont enregistr√©es dans **MongoDB**.
   * Une API REST (`GET /api/contents`) permet la r√©cup√©ration.

4. **Consultation**

   * Via API Gateway (GraphQL) ou `Query Service`, les clients peuvent interroger les contenus.
   * Les resolvers appellent l‚ÄôAPI REST du `Storage Service`.

---

## üõ†Ô∏è Technologies Utilis√©es

| Composant          | Technologie                           |
| ------------------ | ------------------------------------- |
| Langage principal  | Node.js                               |
| Web/API Framework  | Express.js                            |
| API GraphQL        | Apollo Server                         |
| Base de donn√©es    | MongoDB + Mongoose                    |
| Bus de messages    | Apache Kafka + kafkajs                |
| IA / NLP           | LM Studio (local, mod√®le open-source) |
| gRPC Communication | `@grpc/grpc-js`, `@grpc/proto-loader` |
| HTTP Client        | Axios                                 |

---

## ‚öôÔ∏è Pr√©requis

* Node.js v16+
* Apache Kafka & Zookeeper (localhost:9092)
* MongoDB (localhost:27017)
* LM Studio (localhost:1234)

  * Mod√®le charg√© (ex : `deepseek-r1-distill-qwen-7b`)
  * Serveur API actif (ex : `/v1/chat/completions`)

---

## üì¶ Installation

Clonez le d√©p√¥t :

```bash
git clone https://github.com/votre-utilisateur/medical-pipeline.git
cd medical-pipeline
```

Installez les d√©pendances :

```bash
cd api-gateway && npm install
cd ../classifier-service && npm install
cd ../content-receiver && npm install
cd ../storage-service && npm install
cd ../query-service && npm install
```

---

## ‚ñ∂Ô∏è Lancement des Services

**D√©marrage recommand√© dans l‚Äôordre suivant :**

1. Kafka + Zookeeper
2. MongoDB
3. LM Studio (mod√®le charg√©, serveur API actif)
4. Microservices :

```bash
# Dans chaque dossier de service
npm run start
```

---

## üîó Points d'acc√®s API

| Service         | Type         | Port  | URL/Entr√©e                 |
| --------------- | ------------ | ----- | -------------------------- |
| API Gateway     | REST/GraphQL | 8000  | `/api/content`, `/graphql` |
| gRPC Receiver   | gRPC         | 50051 | `ProcessContent()`         |
| Storage Service | REST         | 8001  | `/api/contents`            |
| Query Service   | GraphQL      | 4000  | `/graphql`                 |

---

## üìÅ Structure du Projet (exemple)

```
medical-pipeline/
‚îú‚îÄ‚îÄ api-gateway/
‚îú‚îÄ‚îÄ classifier-service/
‚îú‚îÄ‚îÄ content-receiver/
‚îú‚îÄ‚îÄ query-service/
‚îú‚îÄ‚îÄ storage-service/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ kafka-config.js
‚îî‚îÄ‚îÄ README.md
```

---

## üß© Am√©liorations Possibles

* Ajout de m√©canismes de retry / gestion d‚Äôerreurs (topic `processing-errors`)
* Authentification / s√©curisation des API
* Monitoring (ex: Prometheus + Grafana)
* CI/CD pour d√©ploiement multi-environnement
* Interface Web de visualisation (ex: Next.js + Apollo Client)

---

Souhaitez-vous que je g√©n√®re ce README sous forme de fichier `.md` ?
